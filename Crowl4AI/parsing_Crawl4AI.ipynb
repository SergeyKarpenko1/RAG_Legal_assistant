{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ячейка 2: подключение библиотек и патч для asyncio в Jupyter\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()  # позволяет запускать вложенные циклы asyncio в ноутбуке\n",
    "\n",
    "import asyncio\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from crawl4ai import AsyncWebCrawler, CrawlerRunConfig\n",
    "from crawl4ai.content_scraping_strategy import LXMLWebScrapingStrategy\n",
    "from crawl4ai.deep_crawling import BFSDeepCrawlStrategy\n",
    "from crawl4ai.deep_crawling.filters import FilterChain, URLPatternFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ячейка 3: универсальная функция парсинга одного документа\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "\n",
    "def parse_decision(html: str) -> dict:\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    \n",
    "    # 1) Заголовок / номер дела\n",
    "    h1 = soup.find(\"h1\")\n",
    "    title = h1.get_text(strip=True) if h1 else \"\"\n",
    "    m = re.search(r\"№\\s*([\\d/]+)\", title)\n",
    "    case_number = m.group(1) if m else title or \"—\"\n",
    "    \n",
    "    # 2) Дата\n",
    "    time_tag = soup.find(\"time\")\n",
    "    if time_tag:\n",
    "        date = time_tag.get_text(strip=True)\n",
    "    else:\n",
    "        m2 = re.search(r\"\\b\\d{2}\\.\\d{2}\\.\\d{4}\\b\", html)\n",
    "        date = m2.group(0) if m2 else \"—\"\n",
    "    # Попробуем привести к ISO\n",
    "    try:\n",
    "        date = datetime.strptime(date, \"%d.%m.%Y\").date().isoformat()\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    # 3) Основной блок текста\n",
    "    # Попробуем найти некий контейнер с контентом\n",
    "    body_container = (\n",
    "        soup.find(\"div\", class_=\"doc-content\") or \n",
    "        soup.find(\"div\", class_=\"b-article\") or\n",
    "        soup.find(\"div\", class_=\"content\")\n",
    "    )\n",
    "    if body_container:\n",
    "        paras = [p.get_text(strip=True) for p in body_container.find_all(\"p\")]\n",
    "    else:\n",
    "        # Фолбэк — все параграфы на странице\n",
    "        paras = [p.get_text(strip=True) for p in soup.find_all(\"p\")]\n",
    "    \n",
    "    text = \"\\n\\n\".join(filter(None, paras)) or \"—\"\n",
    "    \n",
    "    # 4) Участники (если есть специфичный список, иначе пусто)\n",
    "    participants = []\n",
    "    for li in soup.select(\"ul.participants li\"):\n",
    "        t = li.get_text(strip=True)\n",
    "        if t:\n",
    "            participants.append(t)\n",
    "    \n",
    "    return {\n",
    "        \"case_number\": case_number,\n",
    "        \"date\": date,\n",
    "        \"participants\": participants,\n",
    "        \"text\": text\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ячейка 4: функция форматирования в Markdown\n",
    "def format_markdown(entry: dict) -> str:\n",
    "    \"\"\"\n",
    "    Возвращает в Markdown только текст решения с разделителем.\n",
    "    \"\"\"\n",
    "    return entry[\"text\"] + \"\\n\\n---\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ячейка 5: асинхронная функция обхода и сохранения в Markdown\n",
    "async def crawl_and_save_md(start_url: str, output_path: str):\n",
    "    # Разрешаем переход только на страницы individual document\n",
    "    url_filter = URLPatternFilter(patterns=[\"*sudrf.cntd.ru/document/*\"])\n",
    "    \n",
    "    strategy = BFSDeepCrawlStrategy(\n",
    "        max_depth=1,               # 0 — список, 1 — документы\n",
    "        include_external=False,\n",
    "        filter_chain=FilterChain([url_filter]),\n",
    "        max_pages=1000              # ограничиваем до 1000 документов\n",
    "    )\n",
    "    config = CrawlerRunConfig(\n",
    "        deep_crawl_strategy=strategy,\n",
    "        scraping_strategy=LXMLWebScrapingStrategy(),\n",
    "        stream=True,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as md_file:\n",
    "        async with AsyncWebCrawler() as crawler:\n",
    "            async for result in await crawler.arun(start_url, config=config):\n",
    "                depth = result.metadata.get(\"depth\", 0)\n",
    "                # пропускаем стартовую страницу списка\n",
    "                if depth == 0 or not result.success:\n",
    "                    continue\n",
    "\n",
    "                parsed = parse_decision(result.html)\n",
    "                # записываем только текст\n",
    "                md_file.write(format_markdown(parsed))\n",
    "                print(f\"✔ {result.url} сохранён ({depth=})\")\n",
    "\n",
    "    print(f\"\\nГотово: сохранено до 1000 документов в «{output_path}»\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Старт краулинга для https://sudrf.cntd.ru/documents?id=901812182 ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080\">INIT</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">]</span><span style=\"color: #008080; text-decoration-color: #008080\">.... → Crawl4AI </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6</span><span style=\"color: #008080; text-decoration-color: #008080\">.</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"color: #008080; text-decoration-color: #008080\"> </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m[\u001b[0m\u001b[36mINIT\u001b[0m\u001b[1;36m]\u001b[0m\u001b[36m...\u001b[0m\u001b[36m. → Crawl4AI \u001b[0m\u001b[1;36m0.6\u001b[0m\u001b[36m.\u001b[0m\u001b[1;36m3\u001b[0m\u001b[36m \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ https://sudrf.cntd.ru/document/1313022993 сохранён (depth=1)\n",
      "✔ https://sudrf.cntd.ru/document/1313125371 сохранён (depth=1)\n",
      "✔ https://sudrf.cntd.ru/document/1313125169 сохранён (depth=1)\n",
      "✔ https://sudrf.cntd.ru/document/1313125332 сохранён (depth=1)\n",
      "✔ https://sudrf.cntd.ru/document/1313125348 сохранён (depth=1)\n",
      "✔ https://sudrf.cntd.ru/document/1313125282 сохранён (depth=1)\n",
      "✔ https://sudrf.cntd.ru/document/1313125358 сохранён (depth=1)\n",
      "✔ https://sudrf.cntd.ru/document/1313125104 сохранён (depth=1)\n",
      "✔ https://sudrf.cntd.ru/document/1313125333 сохранён (depth=1)\n",
      "✔ https://sudrf.cntd.ru/document/1313125224 сохранён (depth=1)\n",
      "✔ https://sudrf.cntd.ru/document/1313125296 сохранён (depth=1)\n",
      "✔ https://sudrf.cntd.ru/document/1313125356 сохранён (depth=1)\n",
      "✔ https://sudrf.cntd.ru/document/1313125306 сохранён (depth=1)\n",
      "✔ https://sudrf.cntd.ru/document/1313125176 сохранён (depth=1)\n",
      "✔ https://sudrf.cntd.ru/document/1313125280 сохранён (depth=1)\n",
      "✔ https://sudrf.cntd.ru/document/1313125389 сохранён (depth=1)\n",
      "✔ https://sudrf.cntd.ru/document/1313125378 сохранён (depth=1)\n",
      "✔ https://sudrf.cntd.ru/document/1313125374 сохранён (depth=1)\n",
      "✔ https://sudrf.cntd.ru/document/1313125377 сохранён (depth=1)\n",
      "✔ https://sudrf.cntd.ru/document/1313125386 сохранён (depth=1)\n",
      "\n",
      "Готово: сохранено до 1000 документов в «court_decisions_obsh_urisdikcii.md»\n",
      "\n",
      "=== Старт краулинга для https://sudrf.cntd.ru/documents?id=780500005 ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080\">INIT</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">]</span><span style=\"color: #008080; text-decoration-color: #008080\">.... → Crawl4AI </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6</span><span style=\"color: #008080; text-decoration-color: #008080\">.</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"color: #008080; text-decoration-color: #008080\"> </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m[\u001b[0m\u001b[36mINIT\u001b[0m\u001b[1;36m]\u001b[0m\u001b[36m...\u001b[0m\u001b[36m. → Crawl4AI \u001b[0m\u001b[1;36m0.6\u001b[0m\u001b[36m.\u001b[0m\u001b[1;36m3\u001b[0m\u001b[36m \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ https://sudrf.cntd.ru/document/1313002290 сохранён (depth=1)\n",
      "✔ https://sudrf.cntd.ru/document/1313002341 сохранён (depth=1)\n",
      "✔ https://sudrf.cntd.ru/document/1313002347 сохранён (depth=1)\n",
      "✔ https://sudrf.cntd.ru/document/1313002330 сохранён (depth=1)\n",
      "✔ https://sudrf.cntd.ru/document/1313002355 сохранён (depth=1)\n",
      "✔ https://sudrf.cntd.ru/document/1313002348 сохранён (depth=1)\n",
      "✔ https://sudrf.cntd.ru/document/1313002313 сохранён (depth=1)\n",
      "✔ https://sudrf.cntd.ru/document/1313002356 сохранён (depth=1)\n",
      "✔ https://sudrf.cntd.ru/document/1313002301 сохранён (depth=1)\n",
      "✔ https://sudrf.cntd.ru/document/1313002311 сохранён (depth=1)\n",
      "✔ https://sudrf.cntd.ru/document/1313002297 сохранён (depth=1)\n",
      "✔ https://sudrf.cntd.ru/document/1313002305 сохранён (depth=1)\n",
      "✔ https://sudrf.cntd.ru/document/1313002293 сохранён (depth=1)\n",
      "✔ https://sudrf.cntd.ru/document/1313002302 сохранён (depth=1)\n",
      "✔ https://sudrf.cntd.ru/document/1313002294 сохранён (depth=1)\n",
      "✔ https://sudrf.cntd.ru/document/1313002306 сохранён (depth=1)\n",
      "✔ https://sudrf.cntd.ru/document/1313003876 сохранён (depth=1)\n",
      "✔ https://sudrf.cntd.ru/document/1313003938 сохранён (depth=1)\n",
      "✔ https://sudrf.cntd.ru/document/1313003935 сохранён (depth=1)\n",
      "✔ https://sudrf.cntd.ru/document/1313003874 сохранён (depth=1)\n",
      "\n",
      "Готово: сохранено до 1000 документов в «court_decisions_arbitrag.md»\n"
     ]
    }
   ],
   "source": [
    "# Ячейка 6: обход сразу двух списков и сохранение в Markdown\n",
    "# Ячейка 6: обход двух списков с новыми именами файлов\n",
    "DOCUMENTS = {\n",
    "    \"901812182\": \"court_decisions_obsh_urisdikcii.md\",\n",
    "    \"780500005\": \"court_decisions_arbitrag.md\"\n",
    "}\n",
    "\n",
    "for doc_id, out_file in DOCUMENTS.items():\n",
    "    start_url = f\"https://sudrf.cntd.ru/documents?id={doc_id}\"\n",
    "    print(f\"\\n=== Старт краулинга для {start_url} ===\")\n",
    "    await crawl_and_save_md(start_url, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Успешно создан файл: court_decisions_combined.md\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def merge_markdown_files(input_paths, output_path, separator='\\n\\n'):\n",
    "    \"\"\"\n",
    "    Объединяет несколько Markdown-файлов в один.\n",
    "    \n",
    "    :param input_paths: список путей к исходным файлам (Path или str)\n",
    "    :param output_path: путь к результирующему файлу (Path или str)\n",
    "    :param separator: строка-разделитель между содержимым файлов\n",
    "    \"\"\"\n",
    "    output_path = Path(output_path)\n",
    "    contents = []\n",
    "\n",
    "    for p in input_paths:\n",
    "        p = Path(p)\n",
    "        if not p.exists():\n",
    "            raise FileNotFoundError(f\"Файл не найден: {p}\")\n",
    "        text = p.read_text(encoding='utf-8')\n",
    "        contents.append(text)\n",
    "\n",
    "    # Объединяем с указанным разделителем\n",
    "    merged_text = separator.join(contents)\n",
    "\n",
    "    # Сохраняем в выходной файл\n",
    "    output_path.write_text(merged_text, encoding='utf-8')\n",
    "    print(f\"Успешно создан файл: {output_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    files_to_merge = [\n",
    "        \"court_decisions_obsh_urisdikcii.md\",\n",
    "        \"court_decisions_arbitrag.md\"\n",
    "    ]\n",
    "    output_file = \"court_decisions_combined.md\"\n",
    "    merge_markdown_files(files_to_merge, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
