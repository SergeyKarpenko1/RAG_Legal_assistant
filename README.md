# RAG-система для правовой помощи

## Введение
Данный проект представляет собой систему RAG (Retrieval-Augmented Generation, генерация с дополненным извлечением), специализирующуюся на правовой помощи, с особым фокусом на обработке и анализе судебных решений на русском языке. Система разработана для помощи юристам и частным лицам в получении релевантной информации из судебных решений на основе запросов на естественном языке.

Проект направлен на улучшение доступа к юридической информации и повышение эффективности работы с правовыми документами путем применения современных технологий обработки естественного языка и машинного обучения.

## Возможности
- Обработка и анализ российских правовых документов, в частности судебных решений
- Специально настроенные модели эмбеддингов (векторных представлений) для российских юридических текстов
- Продвинутые стратегии разделения текста на фрагменты (chunking) с фреймворком для оценки эффективности
- Хранение векторных данных с использованием ChromaDB
- Генерация с дополненным извлечением (RAG) для точного поиска юридической информации
- Поддержка решений как арбитражных судов, так и судов общей юрисдикции
- Интерфейс запросов на естественном языке для получения правовой информации

## Технологии и библиотеки

### Основные фреймворки и архитектура
- **Python**: Основной язык программирования проекта
- **ChromaDB**: Векторная база данных для хранения эмбеддингов документов
- **Jupyter Notebooks**: Используются для разработки и экспериментов
- **RAG-архитектура**: Реализация генерации с дополненным извлечением для правовой помощи

### Используемые библиотеки
Проект использует различные библиотеки, указанные в файле конфигурации `pyproject.toml`, включая:
- Библиотеки для обработки естественного языка
- Инструменты для работы с PDF-документами
- Фреймворки для машинного обучения и настройки моделей эмбеддингов
- ChromaDB для векторного хранилища
- Инструменты для обработки и анализа данных

## Архитектура проекта

Проект имеет следующую структуру директорий и файлов:

```
RAG_Legal_asist/
└── RAG_Legal_assistant/
    ├── Crowl4AI/                  # Сбор данных и парсинг юридических документов
    │   ├── parsing_Crawl4AI.ipynb               # Ноутбук для парсинга юридических документов
    │   ├── court_decisions_combined.txt         # Объединенные судебные решения (текст)
    │   ├── court_decisions_combined.md          # Объединенные судебные решения (markdown)
    │   ├── court_decisions_arbitrag.md          # Решения арбитражных судов
    │   └── court_decisions_obsh_urisdikcii.md   # Решения судов общей юрисдикции
    │
    ├── Data/                      # Юридические документы и хранилище векторной базы данных
    │   ├── chroma_db/             # ChromaDB векторная база данных
    │   │   └── recursive_chunks/  # Данные векторной базы
    │   │
    │   ├── A41-9245-2025_20250520_Reshenija_i_postanovlenija.pdf  # Пример юридического документа
    │   ├── parsed_output.json     # Результаты парсинга документов
    │   └── recursive_chunks.json  # Данные о разделении текста на фрагменты
    │
    ├── Fine_tune_Embeddings/      # Настройка модели эмбеддингов
    │   ├── fine_tune_embrd (2).ipynb             # Ноутбук для тонкой настройки моделей эмбеддингов
    │   ├── Prepear_data.ipynb                    # Подготовка данных для тонкой настройки
    │   ├── RusSyntheticEvaluation.py             # Скрипт оценки для русских синтетических данных
    │   ├── decoded_queries_for_finetune.csv      # Данные запросов для тонкой настройки
    │   └── decoded_queries_Chunking_Evaluation.csv # Данные для оценки
    │
    ├── Notebooks/                 # Jupyter ноутбуки для реализации RAG
    │   ├── RAG.ipynb              # Основной ноутбук реализации RAG
    │   └── money_on_api.ipynb     # Расчет стоимости API
    │
    └── chunking_evaluation/       # Оценка стратегий разделения текста на фрагменты
        └── chunk_eval.ipynb       # Ноутбук для оценки различных стратегий разделения текста
```

### Ключевые компоненты
1. **Сбор и парсинг данных** (Crowl4AI): Инструменты для сбора и анализа юридических документов из различных источников.
2. **Обработка данных** (Data): Хранение и обработка PDF-документов, JSON-выходные данные и стратегии разделения текста.
3. **Настройка моделей эмбеддингов** (Fine_tune_Embeddings): Тонкая настройка моделей для улучшения представления юридических текстов.
4. **Оценка стратегий разделения** (chunking_evaluation): Анализ различных подходов к разделению текста на фрагменты.
5. **Реализация RAG** (Notebooks): Основные ноутбуки для реализации системы генерации с дополненным извлечением.
6. **Векторная база данных** (Data/chroma_db): Хранилище векторных представлений документов с использованием ChromaDB.

## Установка и запуск

### Требования
- Python (версия указана в файле `.python-version`)
- Зависимости, перечисленные в `pyproject.toml`
- Настроенные переменные окружения в файле `.env`

### Шаги по установке
1. Клонировать репозиторий:
   ```bash
   git clone [URL репозитория]
   cd RAG_Legal_assistant
   ```

2. Установить Python указанной версии:
   ```bash
   # Проверить требуемую версию Python
   cat .python-version
   # Установить соответствующую версию Python
   ```

3. Установить зависимости:
   ```bash
   # Если используется Poetry
   poetry install
   
   # Или с помощью pip
   pip install -e .
   ```

4. Настроить переменные окружения:
   ```bash
   # Создать файл .env на основе примера или документации
   # и заполнить необходимые переменные окружения
   ```

### Запуск проекта
Проект в основном используется через Jupyter ноутбуки:

1. Запустить Jupyter:
   ```bash
   jupyter notebook
   ```

2. Открыть и выполнить ноутбуки в следующем порядке:
   - `Crowl4AI/parsing_Crawl4AI.ipynb` для парсинга юридических документов
   - `Fine_tune_Embeddings/Prepear_data.ipynb` для подготовки данных
   - `Fine_tune_Embeddings/fine_tune_embrd (2).ipynb` для настройки моделей эмбеддингов
   - `chunking_evaluation/chunk_eval.ipynb` для оценки стратегий разделения текста
   - `Notebooks/RAG.ipynb` для запуска основной RAG-системы

## Как это работает

RAG-система для правовой помощи работает следующим образом:

1. **Сбор и обработка данных**:
   - Система собирает судебные решения из различных источников
   - Документы обрабатываются и парсятся для извлечения структурированной информации
   - Тексты разделяются на фрагменты (chunks) с использованием оптимизированных стратегий разделения

2. **Построение векторной базы данных**:
   - Для каждого фрагмента текста создается векторное представление (эмбеддинг) с использованием настроенной модели
   - Эмбеддинги сохраняются в векторной базе данных ChromaDB для эффективного поиска

3. **Обработка запросов**:
   - Пользователь вводит запрос на естественном языке (например, юридический вопрос)
   - Запрос преобразуется в векторное представление с использованием той же модели эмбеддингов
   - Система находит наиболее релевантные фрагменты текста в векторной базе данных

4. **Генерация ответа**:
   - Найденные релевантные фрагменты используются для формирования контекста
   - Система генерирует ответ, опираясь на предоставленный контекст и запрос пользователя
   - Ответ содержит релевантную юридическую информацию, извлеченную из судебных решений

### Ключевые процессы

1. **Настройка эмбеддингов**:
   ```python
   # Пример кода для тонкой настройки модели эмбеддингов (из ноутбука)
   model = SentenceTransformer("model_name")
   train_examples = [InputExample(texts=[query, passage]) for query, passage in training_data]
   train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=batch_size)
   train_loss = losses.MultipleNegativesRankingLoss(model)
   model.fit(train_objectives=[(train_dataloader, train_loss)], epochs=epochs)
   ```

2. **Разделение текста на фрагменты**:
   ```python
   # Пример рекурсивного разделения текста (концептуальный пример)
   def recursive_chunk(text, max_chunk_size):
       if len(text) <= max_chunk_size:
           return [text]
       
       # Разделение на логические части (параграфы, предложения и т.д.)
       parts = split_into_logical_parts(text)
       chunks = []
       
       for part in parts:
           if len(part) <= max_chunk_size:
               chunks.append(part)
           else:
               # Рекурсивное разделение больших частей
               chunks.extend(recursive_chunk(part, max_chunk_size))
       
       return chunks
   ```

3. **Поиск релевантных документов**:
   ```python
   # Пример запроса к векторной базе данных (концептуальный пример)
   query_embedding = model.encode(user_query)
   results = chroma_db.query(
       query_embeddings=query_embedding,
       n_results=5
   )
   relevant_chunks = results["documents"][0]
   ```

4. **Генерация ответа**:
   ```python
   # Пример формирования ответа с использованием LLM (концептуальный пример)
   prompt = f"""
   На основе следующей информации из судебных решений, ответьте на вопрос.
   
   Вопрос: {user_query}
   
   Информация:
   {relevant_chunks}
   
   Ответ:
   """
   
   response = llm_model.generate(prompt)
   ```

## Дополнительная информация

Данный проект специализируется на обработке и анализе российских юридических документов, с особым акцентом на решениях судов. Он учитывает особенности юридического языка и структуры правовых документов в российской правовой системе.

Система может быть полезна для:
- Юристов и адвокатов, ищущих прецеденты и релевантную судебную практику
- Исследователей в области права, анализирующих тенденции в судебных решениях
- Частных лиц, нуждающихся в правовой информации по конкретным вопросам

Особое внимание в проекте уделяется:
- Качеству эмбеддингов для русскоязычных юридических текстов
- Эффективным стратегиям разделения текста для сохранения юридического контекста
- Точности поиска релевантной информации в больших объемах судебных решений

## Лицензия

Проект распространяется под лицензией, указанной в файле LICENSE. Пожалуйста, ознакомьтесь с условиями лицензии перед использованием данного программного обеспечения.